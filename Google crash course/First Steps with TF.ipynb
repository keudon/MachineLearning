{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8718cddb",
   "metadata": {},
   "source": [
    "# Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f87cc7e",
   "metadata": {},
   "source": [
    "### Task 1 : create a Linear Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22106203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b9d22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=np.arange(6,21)\n",
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=feature*3+4\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58839bc",
   "metadata": {},
   "source": [
    "### Task 2 : Add some noise to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd305396",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise=2*(2*np.random.random(label.size)-1)\n",
    "print(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aea0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=feature*3+4+noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c87dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb305d7",
   "metadata": {},
   "source": [
    "# Linear Regression with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ec926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fd9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887b5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9d29e0",
   "metadata": {},
   "source": [
    "### Functions definition :\n",
    "`build_model(the_learning_rate)` build an empty model\n",
    "\n",
    "`train_model(model, feature, label, epoch)` train the model with examples (features and label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaddd66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the functions that build and train a model\n",
    "def build_model(the_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential. \n",
    "  # A sequential model contains one or more layers.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Describe the topography of the model.\n",
    "  # The topography of a simple linear regression model\n",
    "  # is a single node in a single layer. \n",
    "  model.add(tf.keras.layers.Dense(units=1, \n",
    "                                  input_shape=(1,)))\n",
    "\n",
    "  # Compile the model topography into code that \n",
    "  # TensorFlow can efficiently execute. Configure \n",
    "  # training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=the_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model           \n",
    "\n",
    "\n",
    "def train_model(model, feature, label, epochs, batch_size):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Feed the feature values and the label values to the \n",
    "  # model. The model will train for the specified number \n",
    "  # of epochs, gradually learning how the feature values\n",
    "  # relate to the label values. \n",
    "  history = model.fit(x=feature,\n",
    "                      y=label,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "  # Gather the trained model's weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the \n",
    "  # rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Gather the history (a snapshot) of each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  # Specifically gather the model's root mean \n",
    "  #squared error at each epoch. \n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "print(\"Defined build_model and train_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce8deb",
   "metadata": {},
   "source": [
    "### Plotting functions definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c50c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the plotting functions\n",
    "def plot_the_model(trained_weight, trained_bias, feature, label):\n",
    "  \"\"\"Plot the trained model against the training feature and label.\"\"\"\n",
    "\n",
    "  # Label the axes.\n",
    "  plt.xlabel(\"feature\")\n",
    "  plt.ylabel(\"label\")\n",
    "\n",
    "  # Plot the feature values vs. label values.\n",
    "  plt.scatter(feature, label)\n",
    "\n",
    "  # Create a red line representing the model. The red line starts\n",
    "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "  x0 = 0\n",
    "  y0 = trained_bias\n",
    "  x1 = my_feature[-1]\n",
    "  y1 = trained_bias + (trained_weight * x1)\n",
    "  plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "  # Render the scatter plot and the red line.\n",
    "  plt.show()\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot the loss curve, which shows loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "  plt.show()\n",
    "\n",
    "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a0cfc6",
   "metadata": {},
   "source": [
    "### Defining dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d498de",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature = [1.0, 2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0, 10.0, 11.0, 12.0]\n",
    "my_label   = [5.0, 8.8,  9.6, 14.2, 18.8, 19.5, 21.4, 26.8, 28.9, 32.0, 33.8, 38.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e6add",
   "metadata": {},
   "source": [
    "### Specify hyperparameters, Build, Train and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b73b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1.0\n",
    "epochs=6\n",
    "my_batch_size=8\n",
    "\n",
    "my_model = build_model(learning_rate)\n",
    "trained_weight, trained_bias, epochs, rmse = train_model(my_model, my_feature, \n",
    "                                                         my_label, epochs,\n",
    "                                                         my_batch_size)\n",
    "plot_the_model(trained_weight, trained_bias, my_feature, my_label)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b9abd2",
   "metadata": {},
   "source": [
    "# Linear Regression with a Real Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant modules\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# The following lines adjust the granularity of reporting. \n",
    "pd.options.display.max_rows = 10\n",
    "pd.options.display.float_format = \"{:.1f}\".format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae93dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv file\n",
    "training_dataset = pd.read_csv(filepath_or_buffer=\"https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a399cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first rows\n",
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the label (label ~ output)\n",
    "# Scaling helps keeping loss values at a frendlier range\n",
    "# Scaling a label is usually not essential\n",
    "# Scaling features in a multi-feature model usualli is essential\n",
    "training_dataset[\"median_house_value\"] /= 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa94a989",
   "metadata": {},
   "source": [
    "### Examining dataset is important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463f0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a309868",
   "metadata": {},
   "source": [
    "Seems that total_rooms, total_bedrooms, maximum values seems too high ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa6af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.drop(training_dataset[\"total_rooms\"].idxmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the functons that build and train a model\n",
    "def build_model(my_learning_rate):\n",
    "  \"\"\"Create and compile a simple linear regression model.\"\"\"\n",
    "  # Most simple tf.keras models are sequential.\n",
    "  model = tf.keras.models.Sequential()\n",
    "\n",
    "  # Describe the topography of the model.\n",
    "  # The topography of a simple linear regression model\n",
    "  # is a single node in a single layer.\n",
    "  model.add(tf.keras.layers.Dense(units=1, \n",
    "                                  input_shape=(1,)))\n",
    "\n",
    "  # Compile the model topography into code that TensorFlow can efficiently\n",
    "  # execute. Configure training to minimize the model's mean squared error. \n",
    "  model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=my_learning_rate),\n",
    "                loss=\"mean_squared_error\",\n",
    "                metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "  return model\n",
    "\n",
    "def train_model(model, df, feature, label, epochs, batch_size):\n",
    "  \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "  # Feed the model the feature and the label.\n",
    "  # The model will train for the specified number of epochs. \n",
    "  history = model.fit(x=df[feature],\n",
    "                      y=df[label],\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=epochs)\n",
    "\n",
    "  # Gather the trained model's weight and bias.\n",
    "  trained_weight = model.get_weights()[0]\n",
    "  trained_bias = model.get_weights()[1]\n",
    "\n",
    "  # The list of epochs is stored separately from the rest of history.\n",
    "  epochs = history.epoch\n",
    "  \n",
    "  # Isolate the error for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  # To track the progression of training, we're going to take a snapshot\n",
    "  # of the model's root mean squared error at each epoch. \n",
    "  rmse = hist[\"root_mean_squared_error\"]\n",
    "\n",
    "  return trained_weight, trained_bias, epochs, rmse\n",
    "\n",
    "print(\"Defined the create_model and traing_model functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1f0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the plotting functions\n",
    "def plot_the_model(trained_weight, trained_bias, feature, label, training_df):\n",
    "  \"\"\"Plot the trained model against 200 random training examples.\"\"\"\n",
    "\n",
    "  # Label the axes.\n",
    "  plt.xlabel(feature)\n",
    "  plt.ylabel(label)\n",
    "\n",
    "  # Create a scatter plot from 200 random points of the dataset.\n",
    "  random_examples = training_df.sample(n=200)\n",
    "  plt.scatter(random_examples[feature], random_examples[label])\n",
    "\n",
    "  # Create a red line representing the model. The red line starts\n",
    "  # at coordinates (x0, y0) and ends at coordinates (x1, y1).\n",
    "  x0 = 0\n",
    "  y0 = trained_bias\n",
    "  x1 = random_examples[feature].max()\n",
    "  y1 = trained_bias + (trained_weight * x1)\n",
    "  plt.plot([x0, x1], [y0, y1], c='r')\n",
    "\n",
    "  # Render the scatter plot and the red line.\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "def plot_the_loss_curve(epochs, rmse):\n",
    "  \"\"\"Plot a curve of loss vs. epoch.\"\"\"\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel(\"Epoch\")\n",
    "  plt.ylabel(\"Root Mean Squared Error\")\n",
    "\n",
    "  plt.plot(epochs, rmse, label=\"Loss\")\n",
    "  plt.legend()\n",
    "  plt.ylim([rmse.min()*0.97, rmse.max()])\n",
    "  plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_model and plot_the_loss_curve functions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfcd465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.01\n",
    "epochs = 20\n",
    "batch_size = 30\n",
    "\n",
    "# Specify the feature and the label.\n",
    "my_feature = \"total_rooms\"  # the total number of rooms on a specific city block.\n",
    "my_label=\"median_house_value\" # the median value of a house on a specific city block.\n",
    "# That is, you're going to create a model that predicts house value based \n",
    "# solely on total_rooms.  \n",
    "\n",
    "# Discard any pre-existing version of the model.\n",
    "my_model = None\n",
    "\n",
    "# Invoke the functions.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, training_dataset, \n",
    "                                         my_feature, my_label,\n",
    "                                         epochs, batch_size)\n",
    "\n",
    "print(\"\\nThe learned weight for your model is %.4f\" % weight)\n",
    "print(\"The learned bias for your model is %.4f\\n\" % bias )\n",
    "\n",
    "plot_the_model(weight, bias, my_feature, my_label,training_dataset)\n",
    "plot_the_loss_curve(epochs, rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616226ff",
   "metadata": {},
   "source": [
    "Here we trained the model to find a corellation between total_rooms and median_house_value. It's giving poor results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce807a",
   "metadata": {},
   "source": [
    "Let's see how this trained model does in the \"real world\"\n",
    "note : here the real world is just a sample from the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_house_values(n, feature, label,training_df):\n",
    "  \"\"\"Predict house values based on a feature.\"\"\"\n",
    "\n",
    "  batch = training_df[feature][10000:10000 + n]\n",
    "  predicted_values = my_model.predict_on_batch(x=batch)\n",
    "\n",
    "  print(\"feature   label          predicted      loss\")\n",
    "  print(\"  value   value          value          (sort of...)\")\n",
    "  print(\"          in thousand$   in thousand$   \")\n",
    "  print(\"--------------------------------------------\")\n",
    "  for i in range(n):\n",
    "    print (\"%5.0f %6.0f %15.0f %15.0f\" % (training_df[feature][10000 + i],\n",
    "    training_df[label][10000 + i],\n",
    "    predicted_values[i][0],\n",
    "    (training_df[label][10000 + i] - predicted_values[i][0])**2/training_df[label][10000 + i] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d60273",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_house_values(10, my_feature, my_label,training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28367c36",
   "metadata": {},
   "source": [
    "Loss can be important...\n",
    "Let's change the feature to train the model on...\n",
    "...\n",
    "..\n",
    "Few tries show that none of the available feature are that accurate to predict the price.\n",
    "\n",
    "Let's try something else then... \n",
    "A SYNTHETIC FEATURE\n",
    "...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53953f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset[\"housing_median_age\"] = training_dataset[\"total_rooms\"] / training_dataset[\"population\"]\n",
    "\n",
    "my_feature = \"housing_median_age\" \n",
    "\n",
    "# Experiment with the hyperparameters.\n",
    "learning_rate = 0.06\n",
    "epochs = 24\n",
    "batch_size = 30\n",
    "\n",
    "# Don't change anything below this line.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, training_dataset, \n",
    "                                         my_feature, my_label,\n",
    "                                         epochs, batch_size)\n",
    "plot_the_model(weight, bias, my_feature, my_label, training_dataset)\n",
    "plot_the_loss_curve(epochs, rmse)\n",
    "\n",
    "predict_house_values(15, my_feature, my_label, training_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c1f99f",
   "metadata": {},
   "source": [
    "It's still not that great ...\n",
    "So let's use some correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9516679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_feature = \"median_income\" \n",
    "\n",
    "# Experiment with the hyperparameters.\n",
    "learning_rate = 1\n",
    "epochs = 12\n",
    "batch_size = 30\n",
    "\n",
    "# Don't change anything below this line.\n",
    "my_model = build_model(learning_rate)\n",
    "weight, bias, epochs, rmse = train_model(my_model, training_dataset, \n",
    "                                         my_feature, my_label,\n",
    "                                         epochs, batch_size)\n",
    "plot_the_model(weight, bias, my_feature, my_label, training_dataset)\n",
    "plot_the_loss_curve(epochs, rmse)\n",
    "\n",
    "predict_house_values(15, my_feature, my_label, training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484ddd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
